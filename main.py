#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Word Document Splitter - Main Entry Point

author: QiyanLiu
date: 2025-08-06

"""

import os
import sys
import time
from pathlib import Path
from word_splitter import DocumentProcessor

try:
    from tqdm import tqdm
except ImportError:
    class tqdm:
        def __init__(self, iterable=None, total=None, desc="", unit=""):
            self.iterable = iterable
            self.total = total or (len(iterable) if iterable else 0)
            self.desc = desc
            self.current = 0
            if desc:
                print(f"{desc}: 0/{self.total}")
        def update(self, n=1):
            self.current += n
            if self.desc:
                print(f"\r{self.desc}: {self.current}/{self.total}", end="", flush=True)
        
        def set_description(self, desc):
            """Set progress bar description"""
            self.desc = desc
            # Display new description immediately
            if desc:
                print(f"\r{desc}: {self.current}/{self.total}", end="", flush=True)
        
        def close(self):
            if self.desc:
                print()  # New line
        
        def __enter__(self):
            return self
        
        def __exit__(self, *args):
             self.close()

def process_documents_with_progress(processor, doc_files, pbar):
    """Document processing function with progress bar"""
    from concurrent.futures import ThreadPoolExecutor, as_completed
    
    # Use thread pool to process multiple documents
    with ThreadPoolExecutor(max_workers=processor.file_thread_count) as executor:
        futures = [executor.submit(process_single_document_with_callback, 
                                 processor, doc_file, pbar) 
                  for doc_file in doc_files]
        
        for future in as_completed(futures):
            try:
                result = future.result()
                # è¿›åº¦æ¡å·²åœ¨å›è°ƒä¸­æ›´æ–°
            except Exception as e:
                print(f"\nâŒ Document processing failed: {e}")
                pbar.update(1)

def process_single_document_with_callback(processor, doc_path, pbar):
    """Process single document and update progress bar"""
    try:
        # Analyze document structure
        doc, chapters = processor.splitter.analyze_document_structure(str(doc_path))
        
        if not chapters:
            pbar.set_description(f"ğŸ“„ è·³è¿‡: {doc_path.name} (æ— ç« èŠ‚)")
            pbar.update(1)
            return f"è·³è¿‡: {doc_path.name}"
        
        # Update progress bar description
        pbar.set_description(f"ğŸ“„ å¤„ç†ä¸­: {doc_path.name} ({len(chapters)} ä¸ªç« èŠ‚)")
        
        # åˆ›å»ºæ–‡æ¡£ä¸“ç”¨çš„è¾“å‡ºç›®å½•
        doc_output_dir = processor.output_dir / doc_path.stem
        doc_output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†ç« èŠ‚
        from concurrent.futures import ThreadPoolExecutor, as_completed
        with ThreadPoolExecutor(max_workers=processor.chapter_thread_count) as executor:
            futures = [executor.submit(processor.splitter.create_chapter_document, 
                                     doc, chapter, str(doc_output_dir))
                      for chapter in chapters]
            
            created_files = []
            for future in as_completed(futures):
                try:
                    result = future.result()
                    created_files.append(result)
                except Exception as e:
                    print(f"\nâŒ Chapter processing failed: {e}")
        
        # Update progress bar
        pbar.set_description(f"âœ… å®Œæˆ: {doc_path.name} ({len(created_files)} ä¸ªæ–‡ä»¶)")
        pbar.update(1)
        
        return f"å®Œæˆ: {doc_path.name} -> {len(created_files)} ä¸ªç« èŠ‚"
        
    except Exception as e:
        pbar.set_description(f"âŒ å¤±è´¥: {doc_path.name}")
        pbar.update(1)
        return f"å¤±è´¥: {doc_path.name}"

def main():
    """Main function - Configure parameters and start document processing"""
    INPUT_DIR = "input"
    OUTPUT_DIR = "output"
    MIN_LEVEL = 5
    FILE_THREAD_COUNT = 4
    CHAPTER_THREAD_COUNT = 4
    if not os.path.exists(INPUT_DIR):
        print(f"é”™è¯¯ï¼šè¾“å…¥ç›®å½• '{INPUT_DIR}' ä¸å­˜åœ¨")
        return
    if not (1 <= MIN_LEVEL <= 6):
        print(f"è­¦å‘Šï¼šMIN_LEVELåº”åœ¨1-6ä¹‹é—´ï¼Œå½“å‰å€¼ï¼š{MIN_LEVEL}ï¼Œä½¿ç”¨é»˜è®¤å€¼3")
        MIN_LEVEL = 3
    if not (1 <= FILE_THREAD_COUNT <= 16):
        print(f"è­¦å‘Šï¼šFILE_THREAD_COUNTåº”åœ¨1-16ä¹‹é—´ï¼Œå½“å‰å€¼ï¼š{FILE_THREAD_COUNT}ï¼Œä½¿ç”¨é»˜è®¤å€¼2")
        FILE_THREAD_COUNT = 2
    if not (1 <= CHAPTER_THREAD_COUNT <= 8):
        print(f"è­¦å‘Šï¼šCHAPTER_THREAD_COUNTåº”åœ¨1-8ä¹‹é—´ï¼Œå½“å‰å€¼ï¼š{CHAPTER_THREAD_COUNT}ï¼Œä½¿ç”¨é»˜è®¤å€¼2")
        CHAPTER_THREAD_COUNT = 2
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    print("\n" + "=" * 60)
    print("ğŸ“„ Wordæ–‡æ¡£æ‹†åˆ†å·¥å…·")
    print("=" * 60)
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {INPUT_DIR}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print(f"ğŸ“Š æœ€å°æ‹†åˆ†å±‚çº§: {MIN_LEVEL}")
    print(f"ğŸ§µ æ–‡æ¡£å¤„ç†çº¿ç¨‹æ•°: {FILE_THREAD_COUNT}")
    print(f"âš¡ ç« èŠ‚å¤„ç†çº¿ç¨‹æ•°: {CHAPTER_THREAD_COUNT}")
    print(f"ğŸš€ æ€»çº¿ç¨‹æ•°: {FILE_THREAD_COUNT * CHAPTER_THREAD_COUNT}")
    print("-" * 60)
    
    try:
        # æ£€æŸ¥è¾“å…¥æ–‡æ¡£
        input_path = Path(INPUT_DIR)
        doc_files = list(input_path.glob('*.docx')) + list(input_path.glob('*.doc'))
        
        if not doc_files:
            print(f"âŒ åœ¨ {INPUT_DIR} ä¸­æœªæ‰¾åˆ°Wordæ–‡æ¡£")
            return
        
        print(f"\nğŸ” å‘ç° {len(doc_files)} ä¸ªæ–‡æ¡£:")
        for i, doc_file in enumerate(doc_files, 1):
            print(f"   {i}. {doc_file.name}")
        
        print(f"\nğŸš€ å¼€å§‹å¤„ç†...")
        
        # åˆ›å»ºæ–‡æ¡£å¤„ç†å™¨
        processor = DocumentProcessor(
            input_dir=INPUT_DIR,
            output_dir=OUTPUT_DIR,
            file_thread_count=FILE_THREAD_COUNT,
            chapter_thread_count=CHAPTER_THREAD_COUNT,
            min_level=MIN_LEVEL
        )
        
        # Process documents with progress bar
        with tqdm(total=len(doc_files), desc="ğŸ“„ Processing documents", unit="docs") as pbar:
            start_time = time.time()
            
            # Rewrite processing method to support progress bar
            process_documents_with_progress(processor, doc_files, pbar)
            
            end_time = time.time()
            elapsed_time = end_time - start_time
        
        print(f"\nâœ… å¤„ç†å®Œæˆï¼")
        print(f"â±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
        print(f"ğŸ“‚ ç»“æœä¿å­˜åœ¨: {os.path.abspath(OUTPUT_DIR)}")
        print("=" * 60)
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print("ğŸ“‹ è¯¦ç»†é”™è¯¯ä¿¡æ¯å·²è®°å½•åˆ° word_splitter.log")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()